{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbf5c9b4-cb2f-4617-9292-d8d90ff9e3a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%store -r params\n",
    "%store -r secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d993799e-c31b-4ca3-a413-b963988340f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.avro.functions import to_avro, from_avro\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46d5d5bf-c8f8-4523-8066-c0cc4d45323b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/31 13:07:25 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Apply Engine\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26e33188-793c-4cdd-ac60-95f24e24120f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_schema(schema_file):\n",
    "    with open(schema_file, 'r') as f:\n",
    "        schema_json = json.load(f)\n",
    "        return StructType.fromJson(schema_json)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "885b994b-02b5-4f62-85e7-c5501ce3bfd0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mainframe_landing_dir = params['mainframe_landing']\n",
    "schema_file = params[\"spark_schema_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a52e5da-cd8e-452a-abe8-4ed8a994f584",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema = read_schema(schema_file)\n",
    "\n",
    "with open(params[\"avro_schema_file\"]) as f:\n",
    "    avsc = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cd4e278-cd5e-49e8-957e-6c294437a0fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.readStream.format(\"csv\")\\\n",
    "    .option(\"cleanSource\",\"archive\")\\\n",
    "    .option(\"sourceArchiveDir\",params[\"apply_archive\"])\\\n",
    "    .option(\"maxFilePerTrigger\", 2)\\\n",
    "    .option(\"header\", True)\\\n",
    "    .schema(schema)\\\n",
    "    .load(mainframe_landing_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6a2b588-f3a6-4faf-8473-f75f3a0c5131",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"dob\", df.dob.cast(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67225a06-256a-4a83-bee4-6d66292fa29c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_avro_kafka_df(src_df, key):\n",
    "    kafka_df = src_df.selectExpr(f\"{key} as key\", \"(struct(*)) as value\")\n",
    "    kafka_df = kafka_df.withColumn(\"key\", kafka_df.key.cast(StringType())).withColumn(\"value\", to_avro(kafka_df.value, avsc))\n",
    "    return kafka_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e37a930-6511-44d4-bd18-48decbb10ff7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "avro_df = get_avro_kafka_df(df, \"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e306dff-7959-4e8e-a1b8-d2b7f119dd19",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "write_checkpoint_location = params[\"checkpoints\"][\"apply_write\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec59e54b-321c-4289-b5d9-7d64255ff5b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/31 13:14:39 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sQuery = (avro_df\n",
    "        .writeStream\n",
    "        .format(\"kafka\")\n",
    "        .queryName(\"apply-engine\")\n",
    "        .option(\"kafka.bootstrap.servers\", secrets[\"RED_KAFKA_SERVERS\"])\n",
    "        .option(\"kafka.sasl.mechanism\", \"PLAIN\")\n",
    "        .option(\"kafka.security.protocol\", \"SASL_SSL\")\n",
    "        .option(\"kafka.sasl.jaas.config\", \"org.apache.kafka.common.security.plain.PlainLoginModule required username='{}' password='{}';\".format(secrets[\"RED_KAFKA_USERNAME\"], secrets[\"RED_KAFKA_PASSWORD\"]))\n",
    "        .option(\"topic\",params[\"topic\"][\"red_landing\"])\n",
    "        .option(\"checkpointLocation\",write_checkpoint_location)\n",
    "        .outputMode(\"append\")\n",
    "        .start()\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "apply-engine",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
