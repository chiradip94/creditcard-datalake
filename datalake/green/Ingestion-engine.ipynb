{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bf05bc8-37a2-4787-9331-191c7ec4ccd4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%store -r params\n",
    "%store -r secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "718bcfe7-740f-4480-9331-69c6816a0e31",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.avro.functions import to_avro, from_avro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00f69070-24f4-443a-b5d8-f8d6c1f8f4e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/31 14:00:00 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Ingestion\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63ad48e6-5bac-4296-85cd-4e908bb5d7c7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "read_checkpoint_location = params[\"checkpoints\"][\"ingestion_read\"]\n",
    "os.makedirs(read_checkpoint_location,exist_ok=True)\n",
    "write_checkpoint_location = params[\"checkpoints\"][\"ingestion_write\"]\n",
    "os.makedirs(write_checkpoint_location,exist_ok=True)\n",
    "\n",
    "with open(params[\"avro_schema_file\"]) as f:\n",
    "    avsc = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f91c384-e77b-4678-9d68-9d4b414d861d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/31 14:05:44 WARN KafkaSourceProvider: Kafka option 'kafka.group.id' has been set on this query, it is\n",
      " not recommended to set this option. This option is unsafe to use since multiple concurrent\n",
      " queries or sources using the same group id will interfere with each other as they are part\n",
      " of the same consumer group. Restarted queries may also suffer interference from the\n",
      " previous run having the same group id. The user should have only one query per group id,\n",
      " and/or set the option 'kafka.session.timeout.ms' to be very small so that the Kafka\n",
      " consumers from the previous query are marked dead by the Kafka group coordinator before the\n",
      " restarted query starts running.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "avro_df = (spark.readStream\n",
    "          .format(\"kafka\")\n",
    "          .option(\"kafka.bootstrap.servers\", secrets[\"GREEN_KAFKA_SERVERS\"])\n",
    "          .option(\"kafka.sasl.mechanism\", \"PLAIN\")\n",
    "          .option(\"kafka.security.protocol\", \"SASL_SSL\")\n",
    "          .option(\"kafka.sasl.jaas.config\", \"org.apache.kafka.common.security.plain.PlainLoginModule required username='{}' password='{}';\".format(secrets[\"GREEN_KAFKA_USERNAME\"], secrets[\"GREEN_KAFKA_PASSWORD\"]))\n",
    "          .option(\"subscribe\", params[\"topic\"][\"green_landing\"])\n",
    "          .option(\"kafka.group.id\", \"ingestion-engine\")\n",
    "          .option('checkpointLocation', read_checkpoint_location)\n",
    "          .load()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "003a5f9a-2d18-4711-8782-246216130e3f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "json_df = avro_df.withColumn(\"value\", from_avro(\"value\", avsc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96d9cb72-04ea-4f34-995e-d2e6caff04ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def upsert(json_table_df, batch_id):\n",
    "    json_table_df.createOrReplaceTempView(\"ingestion_temp_view\")\n",
    "    merge_statement = \"\"\"MERGE INTO creditcard_prod.card_details_raw as Target\n",
    "                         USING ingestion_temp_view as Source\n",
    "                         ON Source.value == Target.value\n",
    "                         WHEN MATCHED THEN\n",
    "                         UPDATE SET *\n",
    "                         WHEN NOT MATCHED THEN\n",
    "                         INSERT *\n",
    "                    \"\"\"\n",
    "    json_table_df.sparkSession.sql(merge_statement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15a76f98-0249-4a76-a5c7-d93316c23f5b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/31 14:05:58 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "24/03/31 14:05:59 WARN KafkaSourceProvider: Kafka option 'kafka.group.id' has been set on this query, it is\n",
      " not recommended to set this option. This option is unsafe to use since multiple concurrent\n",
      " queries or sources using the same group id will interfere with each other as they are part\n",
      " of the same consumer group. Restarted queries may also suffer interference from the\n",
      " previous run having the same group id. The user should have only one query per group id,\n",
      " and/or set the option 'kafka.session.timeout.ms' to be very small so that the Kafka\n",
      " consumers from the previous query are marked dead by the Kafka group coordinator before the\n",
      " restarted query starts running.\n",
      "    \n",
      "24/03/31 14:05:59 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, group.id, auto.offset.reset]' were supplied but are not used yet.\n",
      "24/03/31 14:06:11 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "24/03/31 14:06:12 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "24/03/31 14:06:17 ERROR Schema: Failed initialising database.\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 195 more\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "24/03/31 14:06:17 ERROR Datastore: Exception thrown creating StoreManager. See the nested exception\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 195 more\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "24/03/31 14:06:17 WARN HiveMetaStore: Retrying creating default database after error: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:529)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "NestedThrowablesStackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "24/03/31 14:06:17 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "24/03/31 14:06:17 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "24/03/31 14:06:17 ERROR Schema: Failed initialising database.\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 195 more\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "24/03/31 14:06:17 ERROR Datastore: Exception thrown creating StoreManager. See the nested exception\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 195 more\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "24/03/31 14:06:19 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "24/03/31 14:06:19 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "24/03/31 14:06:19 ERROR Schema: Failed initialising database.\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 195 more\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "24/03/31 14:06:19 ERROR Datastore: Exception thrown creating StoreManager. See the nested exception\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 195 more\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "24/03/31 14:06:19 WARN HiveMetaStore: Retrying creating default database after error: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:529)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "NestedThrowablesStackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "24/03/31 14:06:19 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "24/03/31 14:06:19 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "24/03/31 14:06:19 ERROR Schema: Failed initialising database.\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 195 more\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "24/03/31 14:06:19 ERROR Datastore: Exception thrown creating StoreManager. See the nested exception\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 195 more\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "24/03/31 14:06:21 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "24/03/31 14:06:21 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "24/03/31 14:06:21 ERROR Schema: Failed initialising database.\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 195 more\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "24/03/31 14:06:21 ERROR Datastore: Exception thrown creating StoreManager. See the nested exception\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 195 more\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "24/03/31 14:06:21 WARN HiveMetaStore: Retrying creating default database after error: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:529)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "NestedThrowablesStackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "24/03/31 14:06:21 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "24/03/31 14:06:21 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "24/03/31 14:06:22 ERROR Schema: Failed initialising database.\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 195 more\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "24/03/31 14:06:22 ERROR Datastore: Exception thrown creating StoreManager. See the nested exception\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 195 more\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "24/03/31 14:06:24 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "24/03/31 14:06:24 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "24/03/31 14:06:24 ERROR Schema: Failed initialising database.\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 195 more\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "24/03/31 14:06:24 ERROR Datastore: Exception thrown creating StoreManager. See the nested exception\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 195 more\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "24/03/31 14:06:24 WARN HiveMetaStore: Retrying creating default database after error: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:529)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "NestedThrowablesStackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "24/03/31 14:06:24 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "24/03/31 14:06:24 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "24/03/31 14:06:24 ERROR Schema: Failed initialising database.\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 195 more\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "24/03/31 14:06:24 ERROR Datastore: Exception thrown creating StoreManager. See the nested exception\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 195 more\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "24/03/31 14:06:26 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "24/03/31 14:06:26 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "24/03/31 14:06:26 ERROR Schema: Failed initialising database.\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 195 more\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "24/03/31 14:06:26 ERROR Datastore: Exception thrown creating StoreManager. See the nested exception\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 195 more\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "24/03/31 14:06:26 WARN HiveMetaStore: Retrying creating default database after error: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:529)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "NestedThrowablesStackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "24/03/31 14:06:26 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "24/03/31 14:06:26 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "24/03/31 14:06:26 ERROR Schema: Failed initialising database.\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 195 more\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "24/03/31 14:06:26 ERROR Datastore: Exception thrown creating StoreManager. See the nested exception\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 195 more\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n",
      "------\n",
      "\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:997)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:712)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1171)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1258)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1123)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.SubqueryAlias.mapChildren(basicLogicalOperators.scala:1659)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.MergeIntoTable.mapChildren(v2Commands.scala:716)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1046)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
      "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
      "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
      "\tat jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:681)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 197 more\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 213 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/chiradip/Documents/learn/credit-card/datalake/green/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 210 more\n"
     ]
    }
   ],
   "source": [
    "sQuery = (json_df.writeStream\n",
    "          .queryName(\"Ingestion\")\n",
    "          .foreachBatch(upsert)\n",
    "          .option(\"checkpointLocation\",write_checkpoint_location)\n",
    "          .outputMode(\"append\")\n",
    "          .start()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57e6beac-a411-4415-b948-780d5a8e5342",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#sQuery = (json_df.writeStream\n",
    "#          .queryName(\"Ingestion\")\n",
    "#          .option(\"checkpointLocation\",write_checkpoint_location)\n",
    "#          .outputMode(\"append\")\n",
    "#          .toTable(\"creditcard_prod.card_details_raw\")\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1a5392c-b184-4384-b834-2e515973eb65",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Ingestion-engine",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
